---
title: "Krigeage avec R"
author:
  - name: Eric Marcon
abstract: >
  Techniques pour interpoler les valeurs d'une variable continue.
date: "`r format(Sys.time(), '%d %B %Y')`"
lang: fr-FR
bibliography: references.bib
pdftoc: yes
always_allow_html: yes
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
  bookdown::pdf_book:
    template: latex/template.tex
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: yes
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos="https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, InstallPackage))
}

# Basic packages
InstallPackages(c("bookdown", "formatR", "kableExtra", "ragg"))

# kableExtra must be loaded 
if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
  # Word output (https://stackoverflow.com/questions/35144130/in-knitr-how-can-i-test-for-if-the-output-will-be-pdf-or-word)
  # Do not use autoformat (https://github.com/haozhu233/kableExtra/issues/308)
  options(kableExtra.auto_format = FALSE)
}
library("kableExtra")

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c("kableExtra", "remotes", "tidyverse", "ragg",
          "akima", "spatial", "gstat", "automap", "spatstat", "rgdal", "raster")
# Install them
InstallPackages(Packages)

remotes::install_github("EricMarcon/SpatDiv")

# knitr options
knitr::opts_chunk$set(
  cache = FALSE, # Cache chunk results
  echo = TRUE, # Show/Hide R chunks
  warning = FALSE, # Show/Hide warnings
  # Figure alignment and size
  fig.align = 'center', out.width='80%',
  # Graphic devices (ragg_png is better than standard png)
  dev = c("ragg_png", "pdf"),
  # Code chunk format
  tidy = TRUE, tidy.opts = list(blank = FALSE, width.cutoff = 70),
  size = "scriptsize", knitr.graphics.auto_pdf = TRUE
  )
options(width = 70)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(panel.background = element_rect(fill = "transparent", colour = NA),
             plot.background = element_rect(fill = "transparent", colour = NA))
knitr::opts_chunk$set(dev.args = list(bg = "transparent"))

# Random seed
set.seed(973)
```

Pour cartographier facilement une variable continue, 5 méthodes sont disponibles, dans les packages **akima**, **spatial**, **spatstat**, **gstat** et **automap**.

Des méthodes plus élaborées ne sont pas traitées ici :

- l'estimation d'un modèle de prédiction de la valeur à partir de variables explicatives (krigeage ordinaire ou krigeage universel). Voir l'aide de la fonction `gstat` pour leur utilisation.
- l'estimation bayesienne de ces modèles ou le co-krigeage (estimation de plusieurs variables non indépendantes). Les packages **RGeostats** [^1] ou **INLA** [^2] permettent une modélisation complexe, mais au prix d'un effort bien supérieur.

[^1]: <http://rgeostats.free.fr/>

[^2]: <http://www.r-inla.org/spde-book>


# Interpolation et cartographie locales

## Création des données

Les données représentent le niveau de concentration spatiale locale autour de points [@Marcon2023].

Un jeu de deux types de points est généré dans une fenêtre carrée.
Les cas sont générés par un processus de Matérn [@Matern1960] avec $\kappa$ agrégats (attendus) de $\mu$ points (attendus) dans un cercle de rayon *scale*.
Les contrôles suivent un processus de Poisson dont la densité $\lambda$ décroit exponentiellement vers le haut de la carte.

```{r, message=FALSE}
library("dplyr")
library("dbmss")
# Simulation of cases (clusters)
rMatClust(kappa = 10, scale = 0.05, mu = 10) %>% 
  as.wmppp -> 
  CASES
CASES$marks$PointType <- "Cases"
# Number of points
CASES$n

# Simulation of controls (random distribution)
rpoispp(function(x, y) {1000 * exp(-2 * y)}) %>% 
  as.wmppp ->
  CONTROLS
CONTROLS$marks$PointType <-"Controls"
# Number of points
CONTROLS$n

# Mixed patterns (cases and controls)
ALL <- superimpose(CASES, CONTROLS)
autoplot(ALL)
```

La valeur de la concentration relative autour de chaque cas à la distance $r=0,1$ est définie comme le rapport entre la proportion de cas observés et la proportion moyenne sur tout le domaine d'étude.
Si elle est supérieure à 1, on observe plus de voisins qu'attendu.

La valeur est calculée en chaque point et stockée dans un objet de type `fv` dont les valeurs sont récupérées pour produire un dataframe.

```{r}
# Choose the distance to plot
Distance <- 0.1

# Calculate the M values to plot
ALL %>% 
  Mhat(
    r = c(0, Distance),
    ReferenceType = "Cases",
    NeighborType = "Cases", 
    Individual = TRUE
  ) -> 
  M_TheoEx

# Make a dataframe with x, y and M
the_df <- data.frame(
  x = CASES$x, 
  y = CASES$y, 
  z = as.numeric(as.data.frame(M_TheoEx)[2, -(1:3)])
)
```

A ce stade, nous disposons d'un tableau contenant les coordonnées et une valeur décrivant chaque point.

```{r}
head(the_df)
```

L'objectif est maintenant de cartographier cette valeur.

## Cartographie

### akima

La méthode d'Akima est une interpolation entre les valeurs des points, faite dans chaque triangle constitué par les triplets de points les plus proches.
La valeur des points est conservée.

```{r Akima}
library("akima")
# interp() function
akima_interp <- interp(
  # Coordinates
  x = the_df$x, 
  y = the_df$y, 
  # Value
  z = the_df$z,
  # Coordinates to interpolate
  xo = seq(from = 0, to = 1, by = .01), 
  yo = seq(from = 0, to = 1, by = .01)
)
# Map
image(akima_interp, col = topo.colors(128, alpha = 1), asp = 1)
# Contour lines
contour(akima_interp, add = TRUE)
# Add the points
with(the_df, points(x, y, pch = 20))
```

L'interpolation se limite au polygone convexe contenant les points.

### spatstat

La fonction `Smooth.ppp()` du package **spatstat** permet d'obtenir le même résultat mais ne se limite pas au polygone contenant les points.

Elle s'applique à un objet de type `ppp` (*planar point pattern*) à créer.

```{r, message=FALSE}
library("spatstat")
the_df %>% 
  # Create a ppp in a square window
  as.ppp(W = square(1)) %>% 
  # Smooth it. The bandwidth is computed by bw.scott()
  Smooth(sigma = bw.scott(.)) ->
  spatstat_interp

# Plot the result
plot(spatstat_interp, main = "")
# Contour lines
contour(spatstat_interp, add = TRUE)
# Add the points
with(the_df, points(x, y, pch = 20))
```

Le choix de la largeur de bande est capital. 
La règle de Scott, implémentée dans `bw.scott()` est généralement efficace.


### spatial

Le package **spatial** permet de kriger au lieu de simplement interpoler, mais renvoie des erreurs si la méthode de calcul de la covariance n'est pas exponentielle.
L'ordre du polynôme du modèle et la distance de dépendance doivent être choisis explicitement.

```{r spatial}
library("spatial")
# Function surf.gls() creates a trend surface object
surf.gls(
  np = 3, 
  covmod = expcov,
  x = the_df$x, 
  y = the_df$y, 
  z = the_df$z, 
  d = .5
) %>% 
  # prmat() performs kriging over a grid
  prmat(xl= 0, xu = 1, yl = 0, yu = 1, n = 128) ->
  spatial_krig

# Map it
image(spatial_krig, col = topo.colors(128, alpha = 1), asp = 1)
# Contour lines
contour(spatial_krig, add = TRUE)
# Add the points
with(the_df, points(x, y, pch = 20))
```

### gstat

Le package **gstat** étend les possibilités de krigeage en permettant de spécifier un modèle de tendance pour la variable cartographiée (inutile ici, on utilise `formula=Richness~1`).
Le variogramme doit être calculé et un modèle ajusté (dans l'exemple, un modèle gaussien et non exponentiel).

```{r gstat}
library("sp")
# Create a SpatialPointsDataFrame with the data
sp_spdf <- SpatialPointsDataFrame(
  # Coordinates are x and y
  coords = the_df[, 1:2],
  # Data is z
  data = the_df[3]
)
library("gstat")
# Empirical variogram
gstat::variogram(z ~ 1, data = sp_spdf) %>% 
  # Fit a Gaussian model
  fit.variogram(vgm("Gau")) ->
  gstat_variogram

# Build an oject that describes all features of the model.
# The formula defines the trend
geoX <- gstat(
  formula = z ~ 1, 
  locations = sp_spdf, 
  model = gstat_variogram
)
# Préparation d'une grille de 128 points de côté
xy <- expand.grid((0:128) / 128, (0:128) / 128)
names(xy) <- c("x", "y")
gridded(xy) <- ~ x + y
# Calcul de la valeur de Richness sur les points de la grille (krigeage)
geoXprd <- predict(geoX, newdata = xy)

# Carte
image(geoXprd, col = topo.colors(128, alpha = 1), asp=1)
# Contour lines
contour(spatial_krig, add = TRUE)
# Add the points
with(the_df, points(x, y, pch = 20))
```


### automap

Le package **automap** s'appuie sur **gstat** mais automatise toutes les étapes de sélection du modèle de covariance (celui qui s'ajuste le mieux aux données est choisi).
Le modèle sélectionné est affiché dans le variogramme.
La grille précédente peut être utilisée, mais une grille calculée à partir de la fenêtre de l'objet ``ppp` (librairie **spatstat**) est plutôt utilisée ici.


```{r automap}
library("spatstat")
# Build a ppp object
the_df %>% 
  # Create a ppp in a square window
  as.ppp(W = square(1)) ->
  the_ppp
# Preparing a 256-square-point grid
xy <- gridcentres(the_ppp, 256, 256)
# Filtering of grid nodes inside the window (not necessary here)
ok <- inside.owin(xy$x, xy$y, the_ppp)
# Formatting the grid
sp_grid <- SpatialPoints(cbind(xy$x[ok], xy$y[ok]))
gridded(sp_grid) <- TRUE
# Kriging the SpatialPointsDataFrame
library("automap")
automap_krig <- autoKrige(
  formula = z ~ 1, 
  input_data = sp_spdf, 
  new_data = sp_grid
)
# Result
plot(automap_krig)

# The usual map
image(automap_krig$krige_output, col = topo.colors(128, alpha = 1), asp = 1)
contour(automap_krig$krige_output, add=TRUE)
with(the_df, points(x, y, pch = 20))
```


# Utilisation de fonds de carte

L'objectif est ici d'interpoler une variable continue du même type sur les centroïdes de polygones d'une carte vectorielle (un shapefile) plutôt que sur une grille.

## Obtention des cartes

Le package _raster_ permet de télécharger des fonds de carte administratifs, des modèles numériques de terrain, des cartes de climat : voir l'aide de la fonction `getData`.

```{r France, message=FALSE}
library("raster")
# Retrieving the shapefile for the boundaries of France's regions
France <- raster::getData('GADM', country='FRA', level=3)
# Projection of France in Lambert 93
France <- spTransform(France, CRS("+init=epsg:2154"))
plot(France)
```

## Fabrication des données

Les données sont 100 points placés aléatoirement dans un rectangle contenant la France.
Leur marque est une valeur numérique continue, augmentant linéairement de l'ouest vers l'est et avec la distance à la latitude moyenne, et contenant un bruit gaussien.

```{r spatstat, message=FALSE, tidy=TRUE}
library("spatstat")
# Draw in a Poisson process, 1000 expected points, in a 1x1 window
plot(X <- rpoispp(100), main = "")
# Values of the mark
X$marks <- X$x + 3 * abs(X$y - 0.5) + rnorm(X$n, sd = .1)
# Rough projection on the map
X$x <- 800000 * X$x + 300000
X$y <- 900000 * X$y + 6200000
```

## Interpolation

Les valeurs de $x$, $y$ et $z$ doivent être intégrées dans un objet _Spatial_.

```{r CartePoints}
# Make a spatial point dataframe
SpatialX <- SpatialPointsDataFrame(
  coords = data.frame(x = X$x, y = X$y),
  data = data.frame(m = X$marks), 
  proj4string = CRS("+init=epsg:2154")
)
# Trim it
SpatialX <- SpatialX[France, ]
# Map the points
spplot(SpatialX, "m")
```

L'interpolation est faite avec _gstat_.

```{r gstatmap, warning=FALSE}
library("gstat")
# Empirical variogram
gstat::variogram(m ~ 1, data = SpatialX) %>% 
  # Fit a Gaussian model
  fit.variogram(vgm("Gau")) ->
  gstat_variogram

# Build an oject that describes all features of the model.
geoX <- gstat(
  formula = m ~ 1, 
  locations = SpatialX, 
  model = gstat_variogram
)
# Calculating the value of m on the centroids of polygons
geoXprd <- predict(geoX, newdata = France)
# Final map
spplot(geoXprd, "var1.pred")
```

`r if (!knitr:::is_latex_output()) '# References {-}'`
